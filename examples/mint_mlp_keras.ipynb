{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DeepExplain - Keras (TF backend) example\n",
    "### MNIST with CNN\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tempfile, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "# Import DeepExplain\n",
    "from deepexplain.tensorflow import DeepExplain, ProbDense, ProbDense, ProbActivationRelu\n",
    "\n",
    "#Import DeepLift\n",
    "import deeplift\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from deeplift.util import compile_func\n",
    "\n",
    "from math import pi\n",
    "from scipy.special import erf, erfc\n",
    "exp = np.exp\n",
    "def rect_mean(mus, vs):\n",
    "    assert mus.shape == vs.shape\n",
    "    m = mus\n",
    "    v = vs\n",
    "    s = v**0.5\n",
    "    r1 = s*exp(-(m**2)/(2*v))/(2*pi)**0.5\n",
    "    r2 = 0.5*m*(1+erf(m/((2*v)**0.5)))\n",
    "    return r1 + r2\n",
    "\n",
    "\n",
    "def rect_var(mus, vs):\n",
    "    assert mus.shape == vs.shape\n",
    "    m = mus\n",
    "    v = vs\n",
    "    s = v**0.5\n",
    "    r1 = -v*exp(-(m**2)/v)/(2*pi)\n",
    "    r2 = (-m*s*erf(m/(2*v)**0.5)*exp(-(m**2)/(2*v)))/(2*pi)**0.5\n",
    "    r3 = -0.25*(-2+erfc(m/(2*v)**0.5))*(2*v + m**2 *erfc(m/(2*v)**0.5))\n",
    "    return r1+r2+r3\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 16)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.2566 - acc: 0.5822 - val_loss: 0.8640 - val_acc: 0.7239\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7293 - acc: 0.7629 - val_loss: 0.6381 - val_acc: 0.7980\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6091 - acc: 0.7999 - val_loss: 0.5732 - val_acc: 0.8080\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5474 - acc: 0.8202 - val_loss: 0.5341 - val_acc: 0.8231\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5073 - acc: 0.8325 - val_loss: 0.4787 - val_acc: 0.8445\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4771 - acc: 0.8436 - val_loss: 0.4463 - val_acc: 0.8537\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4554 - acc: 0.8506 - val_loss: 0.4314 - val_acc: 0.8564\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4365 - acc: 0.8564 - val_loss: 0.5519 - val_acc: 0.8023\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4218 - acc: 0.8599 - val_loss: 0.4203 - val_acc: 0.8581\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4072 - acc: 0.8654 - val_loss: 0.4119 - val_acc: 0.8622\n",
      "-5.3124037e-05\n",
      "0.008176558\n",
      "Test loss: 0.41185442802906036\n",
      "Test accuracy: 0.8622\n"
     ]
    }
   ],
   "source": [
    "# Build and train a network.\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "saved_model_file = 'model.h5'\n",
    "saved_model_weights_file = 'model_w.h5'\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 4, 4\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_train])\n",
    "x_test = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_test])\n",
    "\n",
    "\n",
    "\n",
    "#x_train = x_train.reshape(-1, 28,28,1)\n",
    "#x_test = x_test.reshape(-1, 28,28,1)\n",
    "x_train = x_train.reshape(-1, img_rows*img_cols)\n",
    "x_test = x_test.reshape(-1, img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = (x_train - 0.5) * 2\n",
    "x_test = (x_test - 0.5) * 2\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "reg = keras.regularizers.l2(0)\n",
    "def f(x):\n",
    "    return x*tf.sigmoid(x)\n",
    "\n",
    "if SKIP_TRAIN:\n",
    "    model = load_model(saved_model_file)\n",
    "else:\n",
    "    #de.enable_override('shapley')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(img_rows*img_cols,), activation='relu', kernel_regularizer=reg, name='dens_1'))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=reg, name='dens_2'))\n",
    "    model.add(Dense(num_classes, kernel_regularizer=reg, name='dens_3'))\n",
    "    model.add(Activation('softmax'))\n",
    "    # ^ IMPORTANT: notice that the final softmax must be in its own layer \n",
    "    # if we want to target pre-softmax units\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    model.save(saved_model_file)\n",
    "    model.save_weights(saved_model_weights_file)\n",
    "\n",
    "    print (model.layers[0].get_weights()[1].mean())\n",
    "    print (model.layers[0].get_weights()[1].var())\n",
    "    \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x_test[0:3]\n",
    "ys = y_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 16, 10)\n",
      "(3,)\n",
      "(3, 16)\n",
      "Done\n",
      "CPU times: user 792 ms, sys: 32 ms, total: 824 ms\n",
      "Wall time: 630 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = img_rows*img_cols\n",
    "n_classes = 10\n",
    "\n",
    "# Get weights of first dense\n",
    "weights = model.layers[0].get_weights()\n",
    "kernel = weights[0]\n",
    "bias = weights[1]\n",
    "n_output_feat = kernel.shape[1]\n",
    "\n",
    "# Create an equivalent probabilistic model. Notice that\n",
    "# 1. The (probabilistic) input has one more dimension to include both mean and variance\n",
    "# 2. We only keep the non-linearity of the original first dense layer (because the probabilistic input will be computed aside)\n",
    "probInput = Input(shape=(n_output_feat, 2))\n",
    "y = ProbActivationRelu()(probInput)\n",
    "y = ProbDense(128, activation='relu', name='dens_2')(y)\n",
    "y = ProbDense(num_classes, name='dens_3')(y)\n",
    "probModel = Model(inputs=probInput, outputs=y)\n",
    "# ... and load weights in it\n",
    "probModel.load_weights(saved_model_weights_file, by_name=True)\n",
    "\n",
    "# Implement loop to estimate shapley values\n",
    "# Params\n",
    "xn = 50\n",
    "\n",
    "# Flatten MNIST input\n",
    "x = np.copy(xs.reshape(xs.shape[0], -1))\n",
    "# Prepare array for output\n",
    "result = np.zeros(x.shape + (n_classes,))\n",
    "# Count how many input features are there\n",
    "n_input_feat = x.shape[1]\n",
    "# Define sub-coalition sizes\n",
    "Ks = range (0, n_input_feat, max(1, n_input_feat//xn))\n",
    "\n",
    "for j in range(n_input_feat):\n",
    "    for ki in range(len(Ks)):\n",
    "        k = Ks[ki] # coalition size\n",
    "    \n",
    "        x_i = x.copy()\n",
    "        x_i[:, j] = 0\n",
    "        # Dense is essentially a dot product.\n",
    "        # Here, instead of 1, we do 3 dot products\n",
    "        dot = np.dot(x, kernel)\n",
    "        dot_i = np.dot(x_i, kernel)\n",
    "        dot_v = np.dot(x_i ** 2, kernel ** 2)\n",
    "        # Compute mean without feature i\n",
    "        mu = dot_i / (n_input_feat - 1)\n",
    "        # Compensate for number of players in current coalition\n",
    "        mu1 = mu * k\n",
    "        # Compute mean of the distribution that also includes player i (acting as bias to expectation)\n",
    "        mu2 = mu1 + (dot - dot_i)\n",
    "        # Compute variance without player i\n",
    "        v1 = dot_v / (n_input_feat - 1) - mu**2\n",
    "        # Compensate for number or players in the coalition\n",
    "        v1 = v1 * k\n",
    "        # Set something different than 0 if necessary\n",
    "        v1 = np.maximum(0.00001, v1)\n",
    "        # Since player i is only a bias, at this point the variance of the distribution than\n",
    "        # includes it is the same\n",
    "        v2 = v1\n",
    "        \n",
    "        mu1 += bias\n",
    "        mu2 += bias\n",
    "        \n",
    "        x1 = np.stack([mu1, v1], -1)\n",
    "        x2 = np.stack([mu2, v2], -1)\n",
    "        out1 = probModel.predict(x1)\n",
    "        out2 = probModel.predict(x2)\n",
    "        eshap = ((out2[..., 0] - out1[..., 0]) / len(Ks))\n",
    "        result[:, j, :] += eshap\n",
    "\n",
    "print (result.shape)\n",
    "print (np.argmax(ys, 1).shape)\n",
    "a_shap = np.array([result[i, :, c] for i, c in enumerate(np.argmax(ys, 1))])\n",
    "print (a_shap.shape)\n",
    "print ('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.25 µs\n",
      "DeepExplain: running \"grad*input\" explanation method (2)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"intgrad\" explanation method (3)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "Model with multiple inputs:  False\n",
      "DeepLIFT: computing references...\n",
      "DeepLIFT: references ready\n",
      "DeepExplain: running \"deeplift_rc\" explanation method (6)\n",
      "Model with multiple inputs:  False\n",
      "Shapley: computing references...\n",
      "Applying DeepShap on the following ops:  dict_keys(['model_2/dens_1/MatMul', 'model_2/dens_2/MatMul'])\n",
      "revcancel\n",
      "model_2/dens_3/MatMul uses original gradient\n",
      "revcancel\n",
      "Eta shap [revcancel] games[(3, 256, 128)], bias[(128,)], baseline[(3, 256, 128)]\n",
      "Reshape: games[(3, 256, 128)], bias[(128,)], baseline[(3, 256, 128)]\n",
      "revcancel\n",
      "Eta shap [revcancel] games[(3, 16, 256)], bias[(256,)], baseline[(3, 16, 256)]\n",
      "Reshape: games[(3, 16, 256)], bias[(256,)], baseline[(3, 16, 256)]\n",
      "DeepExplain: running \"shapley\" explanation method (7)\n",
      "Model with multiple inputs:  False\n",
      "Shapley: computing references...\n",
      "Applying DeepShap on the following ops:  dict_keys(['model_2/dens_1/MatMul', 'model_2/dens_2/MatMul'])\n",
      "None\n",
      "model_2/dens_3/MatMul uses original gradient\n",
      "None\n",
      "Eta shap [approx] games[(3, 256, 128)], bias[(128,)], baseline[(3, 256, 128)]\n",
      "Reshape: games[(3, 256, 128)], bias[(128,)], baseline[(3, 256, 128)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:413: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  t = (i / (2 * vars[:, :, np.newaxis] * Xs[np.newaxis, np.newaxis, :]) ** 0.5)\n",
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:414: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tb = (ib / (2 * vars[:, :, np.newaxis] * Xs[np.newaxis, np.newaxis, :]) ** 0.5)\n",
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:420: RuntimeWarning: overflow encountered in square\n",
      "  exp1 = e ** -(t ** 2)\n",
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:421: RuntimeWarning: overflow encountered in square\n",
      "  exp2 = e ** -(tb ** 2)\n",
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:453: RuntimeWarning: invalid value encountered in true_divide\n",
      "  eta =  np.where(np.abs(deltas) > 1e-6, shap / deltas, np.zeros_like(shap))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Eta shap [approx] games[(3, 16, 256)], bias[(256,)], baseline[(3, 16, 256)]\n",
      "Reshape: games[(3, 16, 256)], bias[(256,)], baseline[(3, 16, 256)]\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anconam/projects/DeepExplain/deepexplain/tensorflow/deep_shapley.py:414: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tb = (ib / (2 * vars[:, :, np.newaxis] * Xs[np.newaxis, np.newaxis, :]) ** 0.5)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[0].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "\n",
    "    \n",
    "    a_gradin = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('saliency', target_tensor * ys, input_tensor, xs)\n",
    "    a_intgrad = de.explain('intgrad', target_tensor * ys, input_tensor, xs)\n",
    "    a_res = de.explain('deeplift', target_tensor * ys, input_tensor, xs)\n",
    "    a_rc = de.explain('deeplift_rc', target_tensor * ys, input_tensor, xs)\n",
    "    #a_linear = de.explain('linear', target_tensor * ys, input_tensor, xs)\n",
    "    a_layershap = de.explain('shapley', target_tensor * ys, input_tensor, xs)\n",
    "    #a_shap = np.zeros_like(a_linear)\n",
    "    \n",
    "    #attributions2 = de.explain('elrp', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('occlusion', target_tensor * ys, input_tensor, xs)\n",
    "    print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute exacly shapley values!\n",
    "saved_file = 'exact.npy'\n",
    "a_exact = np.zeros_like(a_gradin)\n",
    "if True or not SKIP_TRAIN:\n",
    "    from deepexplain.tensorflow.exact_shapley import compute_shapley\n",
    "    a_exact = np.array([compute_shapley(xx, lambda x: (fModel.predict(np.array(x))*yy).sum(-1)) for xx, yy in zip(xs, ys)])\n",
    "    np.save(saved_file, a_exact)\n",
    "else:\n",
    "    a_exact = np.load(saved_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:24: UserWarning:\n",
      "\n",
      "The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning:\n",
      "\n",
      "Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Exact Shap')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/image.py:395: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/image.py:396: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/image.py:403: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/image.py:408: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/colors.py:902: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/ma/core.py:716: UserWarning:\n",
      "\n",
      "Warning: converting a masked element to nan.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot attributions\n",
    "from utils import plot, plt\n",
    "%matplotlib inline\n",
    "idx = 1\n",
    "# plot(a_gradin[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('GradInput')\n",
    "# plt.figure()\n",
    "plot(a_intgrad[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('IntGrad')\n",
    "plt.figure()\n",
    "plot(a_res[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('DeepLift (Rescale)')\n",
    "#plt.figure()\n",
    "#plot((a_linear)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Linear')\n",
    "plt.figure()\n",
    "plot(a_rc[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('DeepLift (RevCancel)')\n",
    "plt.figure()\n",
    "plot((a_shap)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Deep Shap')\n",
    "plt.figure()\n",
    "# plot((a_layershap)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Layerwise Shap')\n",
    "# plt.figure()\n",
    "#plot((a_shaplud)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('SHAP')\n",
    "#plt.figure()\n",
    "plot((a_exact)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Exact Shap')\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE with DeepShap  0.2288700994484291\n",
      "MSE with DeepLift  0.2927836199298476\n",
      "MSE with DeepLift (Rescale)  4.615019473966188\n",
      "MSE with Int Gradients  4.8594098514479045\n",
      "MSE with GradInput  13.516095859856755\n",
      "Kendall corr.  with DeepShap  0.9277777777777777\n",
      "Kendall corr.  with DeepLift  0.9500000000000001\n",
      "Kendall corr.  with DeepLift (rescale) 0.8388888888888889\n",
      "Kendall corr.  with Int Gradients  0.8277777777777778\n",
      "Kendall corr.  with GradInput  0.7000000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD3CAYAAAAwh5neAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEadJREFUeJzt3W+sHNV5x/Hvb/deY/wHSGKgxnZiKiEk5CSQWgSVKCVQIhcQ9EUUgQRKmlSoUkIhQkJAFaG+q9SKBinpCwsTqICkiIBKUQtYhAghAQWDCX9MUsRfOxBjIgoWwfa99+mLGdONfbl7dn1mdnb295FG3ns9e55z7fvsmTlnZh5FBGbWTp1Rd8DMquMEN2sxJ7hZiznBzVrMCW7WYk5wsxZzgpu1mBPcrMWc4GYt5gQ3a7GpUXfArA3W6PD4kLmkfXex9/6I2FBxlwAnuFkWe5jj61qZtO+/xGsrKu7OR5zgZhkI6EppO9d4f5cT3CyTbmJ+18kJbpaBBIs6iRk+W21fejVmFl3SBkm/kvSSpKtrinmTpJ2SnqsjXk/cNZIekvSCpOclXV5DzMWS/lvSM2XMv6865gHxu5KelnRvjTFflfSspK2Snqw0FsUhespWp0YkuKQu8CPgL4CTgIsknVRD6JuBWmYzDzADXBkRJwGnAd+p4efdA5wZEZ8HTgY2SDqt4pi9Lge21Rhvv69ExMkRsb7KIEWCp211akSCA6cCL0XEyxGxF/gpcEHVQSPiYeB3VceZJ+6bEfFU+fp9il/8VRXHjIjYXX45XW61TPdIWg2cC9xYR7zRSBu9J3IEp/jlfqPn6+1U/AvfFJLWAqcAj9cQqytpK7AT2BwRlccs/QC4ChIXivMJ4AFJWyRdWmUgUSRTypbU3gKnj5KulBSS+i63NSXBJ5KkZcDPgCsi4r2q40XEbEScDKwGTpW0ruqYks4DdkbElqpjzeNLEfEFilO/70j6cpXBMo/gNzPP6aOkNcBXgddTGmlKgu8A1vR8vbr8XmtJmqZI7tsi4q46Y0fEu8BD1DP/cDpwvqRXKU69zpR0aw1xiYgd5Z87gbspTgUrocTz79Rz8AVOH/+Z4mgo6fSqKQn+BHCCpOMlLQIuBO4ZcZ8qI0nAJmBbRFxfU8yjJR1Vvj4cOBt4seq4EXFNRKyOiLUU/68/j4iLq44raamk5ftfU4x6la2WiGKZLGUbOoZ0AbAjIp5JfU8j1sEjYkbSd4H7gS5wU0Q8X3VcST8BzgBWSNoOXBcRm6qOSzGqXQI8W54TA1wbEf9ZYcyVwC3likUHuCMialuyGoFjgbuLz1KmgNsj4r6qgg10JVvx+9a7bLcxIjYu2L60BLiW4oMqvV9+LrrZoft0d3FctewzSfte9t6vt6Qs25UTsPdGxDpJnwUeBD4o/3o18Bvg1Ih46+PaaMQIbjbuinPw6pbAIuJZ4Jj/j6dXgfURsWuh9zXlHNxs7OWcZCtPHx8FTpS0XdK3h+mTR3CzDPZfyZZLRFzU5+/XprTjBDfLQNR/lVoKJ7hZBgPdTVajRp2DV305oeOOLm7bf1bfbJJmJL8EjtvamLXGbeLNJj5EN8sg9yRbLpUkuKYWhxYtG/yN00vpLFkx9JU3644c7n2rjljK51YOH3fYi4WOW76Ez/7Rp4Z6866du/vv9DGOYIqVncOGijsz5L/SMrocreFiAiyfGu5gc0Vnij+ePnyouG/P7uP9uZnktJ2YSTYtWsbUiedX0fSC/mND3XcjFub2ztQec9MPH609JsCuvTU+b6jHGUctqT3mte++kryvBJ1JSXCzySPUwGN0J7hZBhJ0F3VH3Y2DOMHNchAewc1aS6LjBDdrL3WadlmJE9wsCwmP4GZt5nNws5aS5Fl0s9YSaFzvJhtF3TCz8SI63U7SVqe+I3hP3bCzKSqOPCHpnoh4oerOmY2NMV4H/6huGICk/XXDnOBmJY1xgs9XN+yL1XTHbHzVffidItskW/nkjOLm+umluZo1Gw9q5s0mKR85SXXDImJjRKyPiPWaWpyrf2ZjQYLudDdpS2vv4Oqikv5R0ouSfinp7v2lqBaSkuATVTfMbFidrpK2RDdzcHHIzcC6iPgc8Gvgmn6N9D1EH1XdMLOxkvkQPSIeLksX9X7vgZ4vHwO+1q+dpHPwsihelYXxzMZaMYte6yTbt4B/67eTr2Qzy2SAw++Bq4v2kvR3wAxwW799neBmOQx2qequlOqi84aRvgmcB5wVCU/7dIKbZaDyUtVKY0gbgKuAP4uID/rtD05wszw60Ml4N1lZXfQMisP57cB1FLPmhwGbVTzB9bGI+JuF2nGCm2WhrE90+ZjqopsGbccJbpZB8USXFl+qajbZVPcyWRInuFkO9a+DJ3GCm2WR9xw8l0oSfN2Ro6kTdsJ9o/oHXlR7xGdee7r2mAAPvvzOSOLuW1z/WBQXn5u+s0BdP5PNrJUk0Z1uXjo1r0dmY8rn4GZtJc+im7WWcOkis/byCG7WYl4HN2s3X6pq1lKS6HiZzKylfA5u1m6eRTdrKUl0Gnipat+PnPkewG5mB1O3k7TVKSXazRz8AHYz66VmJnhK4YODHsBuZn/Is+hmbdb2WfTe6qKrjnB1UZs8TZxFz9aj3uqin1zi6qI2YSTU6SZtac3NW130k5I2S/qf8s9P9GuneR85ZuOq003b0tzMwZPbVwMPRsQJwIPl1wt3qd8O5QPYHwVOlLRd0rdTe2g2OQSdTtqWICIeBn53wLcvAG4pX98C/GW/dlJm0ed7ALuZ9arnmWzHRsSb5eu3gGP7vcGz6GY5SDCV/PDNQ6ouChARIcnFB83qoMEemzxsddHfSloZEW9KWgns7PcGT7KZ5SByT7LN5x7gG+XrbwD/3u8NHsHNstChJu8ftjZ/ddF/AO4oJ7pfA77erx0nuFkmNVQXBThrkHac4GY5KO8InosT3CwLJ7hZe0loenrUvTiIE9wsh/2z6A1TSYJHBHN7Z6pouo/6q3yOyr65vtc4VGL3nlH8v8J0V7XHHOyfWMk3ktTJI7hZLg28XdQJbpaDPIKbtZhn0c3aS/gQ3aytJKHp5k3yOsHNsvAhulmrNfGhi05wsxx8LbpZy8kjuFlLqZEJnvJU1TWSHpL0gqTnJV1eR8fMxk2ok7TVKWUEnwGujIinJC0HtkjaHBEvVNw3s/Exrufg5WNa3yxfvy9pG7AKcIKb9Rr3WfSyyugpwONVdMZsXAXUfvidIjnBJS0DfgZcERHvzfP3HxUfPG75kmwdNBsLGtNJNgBJ0xTJfVtE3DXfPi4+aBNPnbStRimz6AI2Adsi4vrqu2Q2jpQ1wSV9r1y1ek7STyQNNWqmRDsduAQ4U9LWcjtnmGBmbRadqaStH0mrgL8F1kfEOqALXDhMn1Jm0R+huBnOzD6OVGz5TAGHS9oHLAF+M0wjzZsVMBtXmQ7RI2IH8E/A6xRL1P8bEQ8M0yUnuFkmA1zJtkLSkz3bpb3tSPoERS3w44HjgKWSLh6mT74W3SwLDXKhS7/qon8OvBIRbwNIugv4U+DWQXvlBDfLQeRcAnsdOE3SEuD3FPXInlz4LfNzgptlke9Cl4h4XNKdwFMU94I8DWwcpi0nuFkmKUtgyW1FXEdRMviQOMHNcmjopapOcLNc8q6DZ+EEN8tigkbwXTt3s+mHj1bR9IKeee3p2mPCaAoBrj/3e7XHBDjsiBUjiTs3s7f2mB++8duB9h/r20XNrA8nuFk7hUT4HNyspSKYHVHN9oU4wc0yaV56O8HNsgiggQO4E9wsl4jmZbgT3CwDj+BmLdfA/HaCm2URHsHNWiuAWZ+Dm7VXA/O7f4KXz2N+GDis3P/O8l5VM+sxrofoe4AzI2J3WeHkEUn/FRGPVdw3s7ERMabLZFH0enf55XS5Ne8nMRuxuVF3YB6ptcm6krYCO4HNEeHqomYHKEbx/ludkhI8ImYj4mRgNXCqpHUH7iPp0v3Pef4gmvhZZlad4kKXSNrqNNANrBHxLvAQsGGev/uouuiSBt4Xa1a12Ujb6pRSXfRoSUeVrw8HzgZerLpjZuOmiYfoKbPoK4FbJHUpPhDuiIh7q+2W2XgJgrmMc8/loHojsI7iDOBbETHwc9BSZtF/CZwycA/NJkn+0fkG4L6I+JqkRRQVRgfmK9nMMsl1oYukI4EvA98EiIi9wFBPnfRsmFkGwUDn4AtWF6WoKvo28GNJT0u6UdLSYfrlEdwskwFuNulXXXQK+AJwWVmn7AbgauD7g/bJI7hZBpnXwbcD23suKLuTIuEH5gQ3yyFgdi5t69tUxFvAG5JOLL91FvDCMN3yIbpZBvtH8IwuA24rZ9BfBv5qmEac4GZZRNYHPkTEVmCh8/QkTnCzDCoYwbNwgpvlEGnn13WrJMFnAnbtna2i6QU9+PI7tccE2L1npvaYo6ryuee9XSOJ2120uPaYgzzAIYB9c83LcI/gZhn4uehmbRa4+KBZWwX1P8whhRPcLJO6H+aQwgluloGXyczazOfgZu1VLJM5wc1ayYfoZm0WwZxHcLN2KqqLjroXB3OCm2Uy1ofo5WOTnwR2RMR51XXJbPy0oT745cA24IiK+mI2voJGnoOnFh9cDZxL8SB2MzvA/mWylK1OqSP4D4CrgOUV9sVsbEXmJ7rkklKb7DxgZ0Rs6bPfR9VFP6T+e8HNRqq8ki1lq1PKCH46cL6kc4DFwBGSbo2Ii3t3ioiNwEaAo3VY8z7KzCoUNPNS1b4jeERcExGrI2ItcCHw8wOT22zSxRiP4GaWIHfy5liaHijBI+IXwC+GCWTWZkElo/MhL027solZBhGwd2YuaUuRa2nah+hmGUT++8GzLE17BDfLZIBJtgXLB6cuTafwCG6WwYDn4P3KByctTafwCG6WQQTMzEXS1r+tfEvTHsHNMmnihS5OcLMMImBvBcXJDnVp2glulkFF6+CHzAlulkEFy2RZVJLgy6c6nHHUkiqaXtC+xaP5vJruqvaYczN7a48Jo6nyCTC798P6g8Zgh9wTk+Bmk6a4m8zlg83aKXwObtZaTb0f3AlulsFcwJ7EG0nq5AQ3y2GSZtHNJo3Xwc1azglu1lITdaGL2SQKJ7hZO0VDSxc5wc2yCOYquJvsUCUluKRXgfeBWWCmz9MozCZPC0bwr0TErsp6YjbGgoHvTamFD9HNMolxLD5YCuABSVsOfAKkmfHRIXrKVqfUEfxLEbFD0jHAZkkvRsTDvTuUiX8pwIqODwxs0kQjl8mSRvCI2FH+uRO4Gzh1nn02RsT6iFi/3AluE6Y4B4+krU4p9cGXSlq+/zXwVeC5qjtmNlYCZmfnkrY6pQy1xwJ3S9q//+0RcV+lvTIbQ7lGZ0lrgH+lyL0ANkbEDcO01TfBI+Jl4PPDNG42KSKyTqDNAFdGxFPl0fMWSZsj4oVBG/LJslkmuZbJIuJN4M3y9fuStgGrACe42ahUcaGLpLXAKcDjw7zfCW6WwYA3m6yQ9GTP1xsjYuOBO0laBvwMuCIi3humX05ws0wGmGTrV10USdMUyX1bRNw1bJ+c4GY5RGRbAlOxZLUJ2BYR1x9KWy4fbJZB5gtdTgcuAc6UtLXczhmmXx7BzXKIfOvgEfEIkKUelhPcLJNxvx/czBbQxNtFK0nwV2Y+3HXRrm2vDfHWFcDwD5X4k08P+85Dizu8SYo7jj/rZ1J3jGjm3WSVJHhEHD3M+yQ9OYrHQTluO2PWHdeH6GZtFTGymu0LcYKbZRAEMTc76m4cpGkJftDleo7bmrjt/lkDYrZ5Ca4mzvyZjZtFn1obx2z4ftK+O27/6y11zQs0bQQ3G0/hQ3SzVnOCm7VUeBbdrM2COY/gZi3lc3Cz9ipuF3WCm7VTRCPXwZ3gZpl4BDdrK5+Dm7VXEMzN7Bt1Nw7iBDfLwSO4Wbs5wc3aKpp5oYsfm2yWQVDcLpqypZC0QdKvJL0k6eph++UR3CyHjOfgkrrAj4Czge3AE5LucXVRs5HJOsl2KvBSWbobST8FLsDVRc1GJO/dZKuAN3q+3g58cZiGnOBmGcTv37l/39Yfr0jcfXFKddEcnOBmGUTEhozN7QDW9Hy9uvzewDyLbtY8TwAnSDpe0iLgQuCeYRryCG7WMBExI+m7wP1AF7gpIp4fpi0/VdWsxXyIbtZiTnCzFnOCm7WYE9ysxZzgZi3mBDdrMSe4WYs5wc1a7P8ACK/LY3kn9HkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods = [a_gradin, a_intgrad, a_res, a_rc, a_shap, a_exact]\n",
    "confusion = np.zeros((len(methods), len(methods)))\n",
    "confusion[:] = np.nan\n",
    "confusion_r = np.zeros((len(methods), len(methods)))\n",
    "confusion_r[:] = np.nan\n",
    "\n",
    "n = a_gradin.shape[0]\n",
    "for i, m1 in enumerate(methods):\n",
    "    for j, m2 in enumerate(methods):\n",
    "        if i >= j:\n",
    "            m1 = m1.reshape(n, -1)\n",
    "            m2 = m2.reshape(n, -1)\n",
    "            confusion[i][j] = ((m1-m2)**2).mean()\n",
    "            confusion_r[i][j] = np.mean([scipy.stats.kendalltau(x, y)[0] for x,y in zip(m1, m2)])\n",
    "            confusion[j][i] = confusion[i, j]\n",
    "            confusion_r[j][i] = confusion_r[i, j]\n",
    "plt.figure()\n",
    "plt.matshow(confusion, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.matshow(confusion_r, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "#print ('MSE with SHAP ', confusion[-1][-2])\n",
    "comparison = -1\n",
    "print ('MSE with DeepShap ', confusion[-2][comparison])\n",
    "print ('MSE with DeepLift ', confusion[-3][comparison])\n",
    "print ('MSE with DeepLift (Rescale) ', confusion[-4][comparison])\n",
    "print ('MSE with Int Gradients ', confusion[-5][comparison])\n",
    "print ('MSE with GradInput ', confusion[-6][comparison])\n",
    "\n",
    "#print ('Kendall corr. with SHAP ', confusion_r[-1][-2])\n",
    "print ('Kendall corr.  with DeepShap ', confusion_r[-2][comparison])\n",
    "print ('Kendall corr.  with DeepLift ', confusion_r[-3][comparison])\n",
    "print ('Kendall corr.  with DeepLift (rescale)', confusion_r[-4][comparison])\n",
    "print ('Kendall corr.  with Int Gradients ', confusion_r[-5][comparison])\n",
    "print ('Kendall corr.  with GradInput ', confusion_r[-6][comparison])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running robustness test...\n",
      "Storing robustness results...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow.accuracy_robustness import run_robustness_test\n",
    "original_maps = [a_gradin, a_intgrad, a_res, a_rc, a_shap]\n",
    "names = ['GradInput', 'IntGrad', 'DeepLift (Recale)', 'DeepLift (RevCanc)', 'Deep Shapley']\n",
    "run_robustness_test(fModel, xs, ys, original_maps, names, 'Test', 1,\n",
    "                        result_path='.', mode='prediction', reduce_dim=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running delta test...\n",
      "Done\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow.sensitivityn import run_sensitivity_test\n",
    "run_sensitivity_test(fModel, xs, ys, original_maps, names, 'Test',\n",
    "                        result_path='.', number_of_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n# Compute DeepLift attributions\\nrevealcancel_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\\nrescale_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\\n\\nrevealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\nrescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\n\\na_rc = np.array([np.array(revealcancel_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\n\\na_res = np.array([np.array(rescale_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\nprint (a_rc.shape)\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6d005d2839e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'script'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n# Compute DeepLift attributions\\nrevealcancel_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\\nrescale_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\\n\\nrevealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\nrescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\n\\na_rc = np.array([np.array(revealcancel_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\n\\na_res = np.array([np.array(rescale_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\nprint (a_rc.shape)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2324\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-109>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n# Compute DeepLift attributions\\nrevealcancel_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\\nrescale_model = kc.convert_model_from_saved_files(\\n                            h5_file=saved_model_file,\\n                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\\n\\nrevealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\nrescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\\n\\na_rc = np.array([np.array(revealcancel_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\n\\na_res = np.array([np.array(rescale_func(\\n                task_idx=np.argmax(y),\\n                input_data_list=[[x]],\\n                input_references_list=[[np.zeros_like(x)]],\\n                batch_size=100,\\n                progress_update=None)) for x, y in zip(xs,ys)])\\nprint (a_rc.shape)\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "# Compute DeepLift attributions\n",
    "revealcancel_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\n",
    "rescale_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\n",
    "\n",
    "revealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "rescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "\n",
    "a_rc = np.array([np.array(revealcancel_func(\n",
    "                task_idx=np.argmax(y),\n",
    "                input_data_list=[[x]],\n",
    "                input_references_list=[[np.zeros_like(x)]],\n",
    "                batch_size=100,\n",
    "                progress_update=None)) for x, y in zip(xs,ys)])\n",
    "\n",
    "a_res = np.array([np.array(rescale_func(\n",
    "                task_idx=np.argmax(y),\n",
    "                input_data_list=[[x]],\n",
    "                input_references_list=[[np.zeros_like(x)]],\n",
    "                batch_size=100,\n",
    "                progress_update=None)) for x, y in zip(xs,ys)])\n",
    "print (a_rc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomization test\n",
    "original_attribution = a_shap\n",
    "heatmaps = []\n",
    "the_model = probModel\n",
    "original_weights = {}\n",
    "attribute_f = compute_deepshap\n",
    "\n",
    "plt.figure()\n",
    "plot(original_attribution[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Original')\n",
    "\n",
    "for i, l in enumerate(the_model.layers[::-1]):\n",
    "    if (len(l.get_weights())):\n",
    "        original_weights[i] = l.get_weights()\n",
    "        # Replace weights with random\n",
    "        new_weights = [np.random.normal(size=w.shape) for w in l.get_weights()]\n",
    "        l.set_weights(new_weights)\n",
    "        print (i, l)\n",
    "        a = attribute_f()\n",
    "        plt.figure()\n",
    "        plot(a[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title(str(i))\n",
    "        heatmaps.append(a)\n",
    "        \n",
    "        \n",
    "# Restore weights\n",
    "for i, l in enumerate(the_model.layers[::-1]):\n",
    "    if (len(l.get_weights())):\n",
    "        l.set_weights(original_weights[i])\n",
    "\n",
    "print (\"Correlations\")\n",
    "for attr in heatmaps:\n",
    "    corr = np.mean([scipy.stats.spearmanr(x.flatten(), y.flatten())[0] for x,y in zip(original_attribution, attr)])\n",
    "    print (corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomization test\n",
    "original_attribution = a_gradin\n",
    "heatmaps = []\n",
    "the_model = fModel\n",
    "original_weights = {}\n",
    "print (original_attribution.shape)\n",
    "\n",
    "plt.figure()\n",
    "plot(original_attribution[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Original')\n",
    "\n",
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    for i, l in enumerate(the_model.layers[::-1]):\n",
    "        if (len(l.get_weights())):\n",
    "            original_weights[i] = l.get_weights()\n",
    "            # Replace weights with random\n",
    "            new_weights = [np.random.normal(size=w.shape) for w in l.get_weights()]\n",
    "            l.set_weights(new_weights)\n",
    "            print (i, l.get_weights()[0].shape)\n",
    "            a = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "            plt.figure()\n",
    "            plot(a[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title(str(i))\n",
    "            #print (a[idx])\n",
    "            heatmaps.append(a)\n",
    "        \n",
    "        \n",
    "# Restore weights\n",
    "for i, l in enumerate(the_model.layers[::-1]):\n",
    "    if (len(l.get_weights())):\n",
    "        l.set_weights(original_weights[i])\n",
    "\n",
    "print (\"Correlations\")\n",
    "for attr in heatmaps:\n",
    "    corr = np.mean([scipy.stats.spearmanr(x.flatten(), y.flatten())[0] for x,y in zip(original_attribution, attr)])\n",
    "    print (corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
