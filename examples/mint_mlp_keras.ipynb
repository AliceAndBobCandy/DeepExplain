{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DeepExplain - Keras (TF backend) example\n",
    "### MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tempfile, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "# Import DeepExplain\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "\n",
    "#Import DeepLift\n",
    "import deeplift\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from deeplift.util import compile_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:16: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 16)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 2.1529 - acc: 0.3158 - val_loss: 1.7714 - val_acc: 0.5080\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.5651 - acc: 0.5819 - val_loss: 1.5335 - val_acc: 0.6150\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4033 - acc: 0.6790 - val_loss: 1.3827 - val_acc: 0.7007\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4091 - acc: 0.6955 - val_loss: 1.3367 - val_acc: 0.7101\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.4358 - acc: 0.7039 - val_loss: 1.4867 - val_acc: 0.7159\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.4653 - acc: 0.7076 - val_loss: 1.4387 - val_acc: 0.7230\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.4938 - acc: 0.7118 - val_loss: 1.4787 - val_acc: 0.7242\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5188 - acc: 0.7174 - val_loss: 1.5039 - val_acc: 0.7271\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.5429 - acc: 0.7218 - val_loss: 1.5795 - val_acc: 0.7321\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 1.5637 - acc: 0.7262 - val_loss: 1.5315 - val_acc: 0.7372\n",
      "0.0007720642\n",
      "4.5913157e-06\n"
     ]
    }
   ],
   "source": [
    "# Build and train a network.\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "saved_model_file = 'model.h5'\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 4, 4\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_train])\n",
    "x_test = np.array([scipy.misc.imresize(x, (img_rows,img_cols,)) for x in x_test])\n",
    "\n",
    "\n",
    "\n",
    "#x_train = x_train.reshape(-1, 28,28,1)\n",
    "#x_test = x_test.reshape(-1, 28,28,1)\n",
    "x_train = x_train.reshape(-1, img_rows*img_cols)\n",
    "x_test = x_test.reshape(-1, img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = (x_train - 0.5) * 2\n",
    "x_test = (x_test - 0.5) * 2\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "reg = keras.regularizers.l1(10)\n",
    "def f(x):\n",
    "    return x*tf.sigmoid(x)\n",
    "\n",
    "if SKIP_TRAIN:\n",
    "    model = load_model(saved_model_file)\n",
    "else:\n",
    "    #de.enable_override('shapley')\n",
    "    model = Sequential()\n",
    "    #model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Dense(10, input_shape=(img_rows*img_cols,), activation='relu', bias_regularizer=reg))\n",
    "    model.add(Dense(10, activation='relu', bias_regularizer=reg))\n",
    "    model.add(Dense(num_classes, bias_regularizer=reg))\n",
    "    model.add(Activation('softmax'))\n",
    "    # ^ IMPORTANT: notice that the final softmax must be in its own layer \n",
    "    # if we want to target pre-softmax units\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    model.save(saved_model_file)\n",
    "    print (model.layers[0].get_weights()[1].mean())\n",
    "    print (model.layers[0].get_weights()[1].var())\n",
    "    \n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "aModel = Model(inputs=model.inputs, outputs=[model.layers[1].input])\n",
    "y = aModel.predict(x_test)\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.hist(model.layers[1].get_weights()[0].flatten(), 100)\n",
    "#plt.hist(y.flatten(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define what to be explained\n",
    "xs = x_test[0:30]\n",
    "ys = y_test[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Heads-up: I assume softmax is the output layer, not an intermediate one; if it's an intermediate layer, please let me know and I will prioritise that use-case\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: I assume softmax is the output layer, not an intermediate one; if it's an intermediate layer, please let me know and I will prioritise that use-case\n",
      "(30, 1, 16)\n"
     ]
    }
   ],
   "source": [
    "# Compute DeepLift attributions\n",
    "revealcancel_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\n",
    "rescale_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.Rescale)\n",
    "\n",
    "revealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "rescale_func = rescale_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "\n",
    "a_rc = np.array([np.array(revealcancel_func(\n",
    "                task_idx=np.argmax(y),\n",
    "                input_data_list=[[x]],\n",
    "                input_references_list=[[np.zeros_like(x)]],\n",
    "                batch_size=100,\n",
    "                progress_update=None)) for x, y in zip(xs,ys)])\n",
    "\n",
    "a_res = np.array([np.array(rescale_func(\n",
    "                task_idx=np.argmax(y),\n",
    "                input_data_list=[[x]],\n",
    "                input_references_list=[[np.zeros_like(x)]],\n",
    "                batch_size=100,\n",
    "                progress_update=None)) for x, y in zip(xs,ys)])\n",
    "print (a_rc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.34 µs\n",
      "{'Softplus': 'DeepExplainGrad', 'Elu': 'DeepExplainGrad', 'MatMul': 'MatMulDeepExplainGrad', 'Tanh': 'DeepExplainGrad', 'Relu': 'DeepExplainGrad', 'Sigmoid': 'DeepExplainGrad'}\n",
      "DeepExplain: running \"grad*input\" explanation method (2)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"intgrad\" explanation method (3)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"linear\" explanation method (7)\n",
      "Model with multiple inputs:  False\n",
      "DeepExplain: running \"shapley\" explanation method (6)\n",
      "Model with multiple inputs:  False\n",
      "Shapley: computing references...\n",
      "model_2/dense_2/MatMul_x (1, 10)\n",
      "model_2/dense_2/MatMul_w (10, 10)\n",
      "model_2/dense_3/MatMul_b (10,)\n",
      "model_2/dense_2/MatMul_b (10,)\n",
      "model_2/dense_3/MatMul_w (10, 10)\n",
      "model_2/dense_1/MatMul_w (16, 10)\n",
      "model_2/dense_1/MatMul_x (1, 16)\n",
      "model_2/dense_1/MatMul_b (10,)\n",
      "model_2/dense_3/MatMul_x (1, 10)\n",
      "Shapley: references ready\n",
      "Matmul override:  model_2/dense_3/MatMul\n",
      "\t skipping...\n",
      "Matmul override:  model_2/dense_2/MatMul\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Estimating shape. Input shape:  (10, 10)\n",
      "Return\n",
      "Matmul override:  model_2/dense_1/MatMul\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Estimating shape. Input shape:  (16, 10)\n",
      "Return\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[0].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "\n",
    "    \n",
    "    a_gradin = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('saliency', target_tensor * ys, input_tensor, xs)\n",
    "    a_intgrad = de.explain('intgrad', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions2 = de.explain('deeplift', target_tensor * ys, input_tensor, xs)\n",
    "    a_linear = de.explain('linear', target_tensor * ys, input_tensor, xs)\n",
    "    a_shap = de.explain('shapley', target_tensor * ys, input_tensor, xs)\n",
    "    #a_shap = np.zeros_like(a_linear)\n",
    "    \n",
    "    #attributions2 = de.explain('elrp', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('occlusion', target_tensor * ys, input_tensor, xs)\n",
    "    print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Shapley\n"
     ]
    }
   ],
   "source": [
    "# Compute exacly shapley values!\n",
    "\n",
    "from deepexplain.tensorflow.exact_shapley import compute_shapley\n",
    "a_exact = np.array([compute_shapley(xx, lambda x: (fModel.predict(np.array([x]))*yy).sum()) for xx, yy in zip(xs, ys)])\n",
    "#a_exact = np.zeros_like(a_gradin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot attributions\n",
    "from utils import plot, plt\n",
    "%matplotlib inline\n",
    "idx = 3\n",
    "plot(a_gradin[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('GradInput')\n",
    "plt.figure()\n",
    "plot(a_intgrad[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('IntGrad')\n",
    "plt.figure()\n",
    "plot(a_res[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('DeepLift (Rescale)')\n",
    "plt.figure()\n",
    "plot((a_linear)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Linear')\n",
    "plt.figure()\n",
    "plot(a_rc[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('DeepLift (RevCancel)')\n",
    "plt.figure()\n",
    "plot((a_shap)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Deep Shap')\n",
    "plt.figure()\n",
    "plot((a_exact)[idx].reshape(img_rows, img_cols), xs[idx].reshape(img_rows, img_cols)).title('Exact Shap')\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods = [a_intgrad, a_res,a_linear, a_rc, a_shap, a_exact]\n",
    "confusion = np.zeros((len(methods), len(methods)))\n",
    "confusion_r = np.zeros((len(methods), len(methods)))\n",
    "n = a_gradin.shape[0]\n",
    "for i, m1 in enumerate(methods):\n",
    "    for j, m2 in enumerate(methods):\n",
    "        m1 = m1.reshape(n, -1)\n",
    "        m2 = m2.reshape(n, -1)\n",
    "        confusion[i][j] = ((m1-m2)**2).mean()\n",
    "        confusion_r[i][j] = np.mean([scipy.stats.pearsonr(x, y)[0] for x,y in zip(m1, m2)])\n",
    "plt.figure()\n",
    "plt.matshow(confusion, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.matshow(confusion_r, cmap='RdBu_r')\n",
    "plt.colorbar()\n",
    "print ('Diff with DeepShap ', confusion[-1][-2])\n",
    "print ('Diff with DeepLift ', confusion[-1][-3])\n",
    "print ('Diff with Int Gradients ', confusion[-1][1])\n",
    "\n",
    "print ('Pearson with DeepShap ', confusion_r[-1][-2])\n",
    "print ('Pearson with DeepLift ', confusion_r[-1][-3])\n",
    "print ('Pearson with Int Gradients ', confusion_r[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepexplain.tensorflow.accuracy_robustness import run_robustness_test\n",
    "original_maps = [a_gradin, a_intgrad, a_res, a_linear, a_rc, a_shap, a_exact]\n",
    "names = ['GradInput', 'IntGrad', 'DeepLift (Recale)','Linear', 'DeepLift (RevCanc)', 'ApprShapley', 'Shapley']\n",
    "run_robustness_test(fModel, xs, ys, original_maps, names, 'Test', 1,\n",
    "                        result_path='.', mode='prediction', reduce_dim=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepexplain.tensorflow.sensitivityn import run_sensitivity_test\n",
    "run_sensitivity_test(fModel, xs, ys, original_maps, names, 'Test',\n",
    "                        result_path='.', number_of_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
