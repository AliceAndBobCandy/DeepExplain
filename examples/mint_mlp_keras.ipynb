{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DeepExplain - Keras (TF backend) example\n",
    "### MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tempfile, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Import DeepExplain\n",
    "from deepexplain.tensorflow import DeepExplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4560 - acc: 0.8608 - val_loss: 0.2486 - val_acc: 0.9272\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2255 - acc: 0.9326 - val_loss: 0.1908 - val_acc: 0.9423\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1730 - acc: 0.9484 - val_loss: 0.1517 - val_acc: 0.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110c44cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train a network.\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 3\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = (x_train - 0.5) * 2\n",
    "x_test = (x_test - 0.5) * 2\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(28*28,), activation='relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "# ^ IMPORTANT: notice that the final softmax must be in its own layer \n",
    "# if we want to target pre-softmax units\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Relu': 'DeepExplainGrad', 'Elu': 'DeepExplainGrad', 'Sigmoid': 'DeepExplainGrad', 'Tanh': 'DeepExplainGrad', 'Softplus': 'DeepExplainGrad', 'MatMul': 'MatMulDeepExplainGrad'}\n",
      "DeepExplain: running \"deeplift\" explanation method (5)\n",
      "Model with multiple inputs:  False\n",
      "DeepLIFT: computing references...\n",
      "[<tf.Operation 'dense_1/Relu' type=Relu>, <tf.Operation 'model_1/dense_1/Relu' type=Relu>, <tf.Operation 'model_2/dense_1/Relu' type=Relu>]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{'dense_1/Relu': array([[-3.5257873e-03, -9.9687530e-03, -3.4327679e-03,  5.4856981e-03,\n",
      "        -2.3860009e-03, -3.9335107e-03, -1.8729912e-03, -6.1389152e-03,\n",
      "         3.2475386e-03, -9.8556140e-04,  1.1430808e-02, -5.2354033e-03,\n",
      "         2.1997928e-03,  7.9281889e-03, -4.3562711e-03,  1.6069803e-03,\n",
      "        -1.8807998e-03,  6.9454312e-03, -1.0342950e-02,  4.5372890e-03,\n",
      "        -1.4418813e-03,  6.0224403e-03, -2.7589258e-03,  9.9924777e-04,\n",
      "        -5.8583501e-03,  4.7100568e-03, -7.7593871e-03,  6.4571300e-03,\n",
      "         4.4763554e-05, -4.8732311e-03,  6.8394621e-03, -6.0569784e-03,\n",
      "        -3.6011965e-03, -7.2865626e-03, -4.0916405e-03, -1.2413019e-02,\n",
      "        -3.4011763e-03,  9.6995523e-03,  6.1131772e-03,  5.0129220e-03,\n",
      "         2.6248035e-03,  1.9254646e-04,  4.6200710e-03, -2.6553227e-03,\n",
      "        -1.2789055e-03, -5.6055682e-03, -4.9145818e-03, -4.9828966e-03,\n",
      "         5.1917145e-03,  4.1357866e-03,  4.8116531e-04, -1.7026262e-03,\n",
      "        -7.0337281e-03, -5.2136434e-03,  2.9445139e-03, -5.4636328e-03,\n",
      "        -1.2157764e-02,  1.1219041e-03, -5.8598951e-03, -1.0604701e-02,\n",
      "         1.6174095e-02, -4.8147589e-03, -1.0120081e-03, -3.6831209e-03]],\n",
      "      dtype=float32), 'model_1/dense_1/Relu': array([[-3.5257873e-03, -9.9687530e-03, -3.4327679e-03,  5.4856981e-03,\n",
      "        -2.3860009e-03, -3.9335107e-03, -1.8729912e-03, -6.1389152e-03,\n",
      "         3.2475386e-03, -9.8556140e-04,  1.1430808e-02, -5.2354033e-03,\n",
      "         2.1997928e-03,  7.9281889e-03, -4.3562711e-03,  1.6069803e-03,\n",
      "        -1.8807998e-03,  6.9454312e-03, -1.0342950e-02,  4.5372890e-03,\n",
      "        -1.4418813e-03,  6.0224403e-03, -2.7589258e-03,  9.9924777e-04,\n",
      "        -5.8583501e-03,  4.7100568e-03, -7.7593871e-03,  6.4571300e-03,\n",
      "         4.4763554e-05, -4.8732311e-03,  6.8394621e-03, -6.0569784e-03,\n",
      "        -3.6011965e-03, -7.2865626e-03, -4.0916405e-03, -1.2413019e-02,\n",
      "        -3.4011763e-03,  9.6995523e-03,  6.1131772e-03,  5.0129220e-03,\n",
      "         2.6248035e-03,  1.9254646e-04,  4.6200710e-03, -2.6553227e-03,\n",
      "        -1.2789055e-03, -5.6055682e-03, -4.9145818e-03, -4.9828966e-03,\n",
      "         5.1917145e-03,  4.1357866e-03,  4.8116531e-04, -1.7026262e-03,\n",
      "        -7.0337281e-03, -5.2136434e-03,  2.9445139e-03, -5.4636328e-03,\n",
      "        -1.2157764e-02,  1.1219041e-03, -5.8598951e-03, -1.0604701e-02,\n",
      "         1.6174095e-02, -4.8147589e-03, -1.0120081e-03, -3.6831209e-03]],\n",
      "      dtype=float32), 'model_2/dense_1/Relu': array([[-3.5257873e-03, -9.9687530e-03, -3.4327679e-03,  5.4856981e-03,\n",
      "        -2.3860009e-03, -3.9335107e-03, -1.8729912e-03, -6.1389152e-03,\n",
      "         3.2475386e-03, -9.8556140e-04,  1.1430808e-02, -5.2354033e-03,\n",
      "         2.1997928e-03,  7.9281889e-03, -4.3562711e-03,  1.6069803e-03,\n",
      "        -1.8807998e-03,  6.9454312e-03, -1.0342950e-02,  4.5372890e-03,\n",
      "        -1.4418813e-03,  6.0224403e-03, -2.7589258e-03,  9.9924777e-04,\n",
      "        -5.8583501e-03,  4.7100568e-03, -7.7593871e-03,  6.4571300e-03,\n",
      "         4.4763554e-05, -4.8732311e-03,  6.8394621e-03, -6.0569784e-03,\n",
      "        -3.6011965e-03, -7.2865626e-03, -4.0916405e-03, -1.2413019e-02,\n",
      "        -3.4011763e-03,  9.6995523e-03,  6.1131772e-03,  5.0129220e-03,\n",
      "         2.6248035e-03,  1.9254646e-04,  4.6200710e-03, -2.6553227e-03,\n",
      "        -1.2789055e-03, -5.6055682e-03, -4.9145818e-03, -4.9828966e-03,\n",
      "         5.1917145e-03,  4.1357866e-03,  4.8116531e-04, -1.7026262e-03,\n",
      "        -7.0337281e-03, -5.2136434e-03,  2.9445139e-03, -5.4636328e-03,\n",
      "        -1.2157764e-02,  1.1219041e-03, -5.8598951e-03, -1.0604701e-02,\n",
      "         1.6174095e-02, -4.8147589e-03, -1.0120081e-03, -3.6831209e-03]],\n",
      "      dtype=float32)}\n",
      "DeepLIFT: references ready\n"
     ]
    }
   ],
   "source": [
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[0].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "    xs = x_test[0:1]\n",
    "    ys = y_test[0:1]\n",
    "    \n",
    "    #attributions = de.explain('grad*input', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('saliency', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('intgrad', target_tensor * ys, input_tensor, xs)\n",
    "    attributions = de.explain('deeplift', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('shapley', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('elrp', target_tensor * ys, input_tensor, xs)\n",
    "    #attributions = de.explain('occlusion', target_tensor * ys, input_tensor, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBY/kaFY/ESGYvETGYrFT2So/wfwYeS1kHSswAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot attributions\n",
    "from utils import plot, plt\n",
    "%matplotlib inline\n",
    "plot(attributions.reshape(28,28), xs.reshape(28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
